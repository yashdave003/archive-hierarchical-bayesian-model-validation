{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Assign directory\n",
    "import os\n",
    "BRANDON = '/Users/brandonmarks/Desktop/Research Materials/hierarchical-bayesian-model-validation/'\n",
    "YASH = '/Users/yashd/Desktop/hierarchical-bayesian-model-validation/'\n",
    "HANNAH = ''\n",
    "ZIXUN = ''\n",
    "\n",
    "ROOT_DIR = BRANDON\n",
    "os.chdir(ROOT_DIR + 'testing-framework/')\n",
    "\n",
    "DATA_NAME = 'full-pastis-gray-wavelet'\n",
    "GROUP = 'layer'\n",
    "SKIP_OPTIMIZE_STEP = True\n",
    "\n",
    "# os.mkdir(DATA_NAME)\n",
    "# os.mkdir(os.path.join(DATA_NAME, \"CSVs\"))\n",
    "# os.mkdir(os.path.join(DATA_NAME, \"plots\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "''' Comment out the USE_MATLAB within utilities.py if you do not have MATLAB installed'''\n",
    "from utilities import *\n",
    "from plot_utilities import *\n",
    "\n",
    "np.random.seed(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "group_data_map = pd.read_pickle(f'approx1e5-{DATA_NAME}/group_data_map.pickle')\n",
    "min_group, max_group = 2, sorted(group_data_map)[-1]\n",
    "group_data_map"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{2: array([-99.93568594, -91.00645124, -88.54430615, ...,  88.80035968,\n",
       "         91.52850405,  94.44944672]),\n",
       " 3: array([-76.13432886, -63.02074639, -60.52416619, ...,  65.19608846,\n",
       "         65.26965934,  69.44498554]),\n",
       " 4: array([-51.73647153, -48.46756551, -45.83266202, ...,  48.25087164,\n",
       "         50.33643736,  64.88734264]),\n",
       " 5: array([-47.95678457, -36.2290875 , -34.21402956, ...,  32.91894773,\n",
       "         36.11999915,  42.17747737]),\n",
       " 6: array([-23.87540781, -21.69502371, -19.77842932, ...,  18.532206  ,\n",
       "         21.00124659,  44.79754701]),\n",
       " 7: array([-19.12997336, -11.63154378, -10.24156022, ...,  10.34018388,\n",
       "         11.58181396,  20.30569957]),\n",
       " 8: array([-18.71256003,  -5.38310051,  -4.75432793, ...,   4.71546986,\n",
       "          5.46900035,  20.5891778 ])}"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def bootstrap_metric(x, metric=None, n_bootstrap=10000, ci=0.95, replace=True, sample_max = np.inf):\n",
    "    metric_values = []\n",
    "    sample_size = min(sample_max, len(x))\n",
    "        \n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        resampled = np.random.choice(x, size=sample_size, replace=replace)\n",
    "        metric_values.append(metric(resampled))\n",
    "    \n",
    "    metric_point_estimate = metric(x)\n",
    "    ci_lower = np.percentile(metric_values, (1 - ci) / 2 * 100)\n",
    "    ci_upper = np.percentile(metric_values, (1 + ci) / 2 * 100)\n",
    "    \n",
    "    return metric_point_estimate, ci_lower, ci_upper, metric_values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "n_bootstrap = 100000\n",
    "ci = 0.99\n",
    "group_name = 4\n",
    "print(len(group_data_map[group_name]))\n",
    "n_samp_max = 10000"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50880\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for i in np.arange(min_group, max_group+1):\n",
    "    print(len(group_data_map[i]))\n",
    "    obs_var, var_lower, var_upper, var_values = bootstrap_metric(group_data_map[i], n_bootstrap=n_bootstrap, metric=np.var, ci=ci)\n",
    "    print(f\"Layer {i} Using Full Sample Size: ({var_lower},{var_upper})\")\n",
    "    obs_var, var_lower, var_upper, var_values = bootstrap_metric(group_data_map[i], n_bootstrap=n_bootstrap, metric=np.var, ci=ci,sample_max = n_samp_max)\n",
    "    print(f\"Layer {i} Using {min(n_samp_max, len(group_data_map[i]))} Sample Size: ({var_lower},{var_upper})\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3180\n",
      "Layer 2 Using Full Sample Size: (751.3789238252615,857.0285276556816)\n",
      "Layer 2 Using 3180 Sample Size: (751.5203499026375,856.8665507389957)\n",
      "12720\n",
      "Layer 3 Using Full Sample Size: (265.73779541225673,285.0573803282567)\n",
      "Layer 3 Using 10000 Sample Size: (264.46092812111715,286.3021210042489)\n",
      "50880\n",
      "Layer 4 Using Full Sample Size: (79.16978407812756,82.54005282240888)\n",
      "Layer 4 Using 10000 Sample Size: (77.08617951873491,84.68638678429392)\n",
      "100000\n",
      "Layer 5 Using Full Sample Size: (19.517707866250113,20.253180028097905)\n",
      "Layer 5 Using 10000 Sample Size: (18.753963345918056,21.053013415398524)\n",
      "100000\n",
      "Layer 6 Using Full Sample Size: (4.086727742339456,4.297766064724505)\n",
      "Layer 6 Using 10000 Sample Size: (3.8890937229250193,4.5832305542724825)\n",
      "100000\n",
      "Layer 7 Using Full Sample Size: (0.7947252370845679,0.8468984811703122)\n",
      "Layer 7 Using 10000 Sample Size: (0.7476026180660397,0.9163727528594923)\n",
      "100000\n",
      "Layer 8 Using Full Sample Size: (0.1262709300709894,0.15442822880003637)\n",
      "Layer 8 Using 10000 Sample Size: (0.11729458638248237,0.21151511427827893)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "obs_var, var_lower, var_upper, var_values = bootstrap_metric(group_data_map[4], n_bootstrap=n_bootstrap, metric=lambda x: 1, ci=ci)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "obs_var, var_lower, var_upper, var_values = bootstrap_metric(group_data_map[4], n_bootstrap=n_bootstrap, metric= np.var, ci=ci)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "len(group_data_map[4])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50880"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "x = np.random.randn(100000)\n",
    "samples = np.random.choice(group_data_map[4], size=(50880, x.shape[0]), replace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.14 64-bit ('Research': conda)"
  },
  "interpreter": {
   "hash": "83635bb4831aedbea94bec2369092292994a8fbbb881bb3adfcb1b33cd30abe3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}