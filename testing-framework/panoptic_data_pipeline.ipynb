{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import *\n",
    "from plot_utilities import *\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the code below assumes you are in the \"testing-framework\" directory. Can check Current Working Directory below:\n",
    "# Should be testing-framework\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pd.read_pickle('../data/Panoptic Agriculture/Transformed Dataset/Panoptic_Data_Dict_Normalized.pickle')\n",
    "# obs_x_dict = dict()\n",
    "# for layer in np.arange(2, 9):\n",
    "#     obs_x_dict[layer] = create_obs_x(data_dict, layer)\n",
    "# pd.to_pickle(obs_x_dict, 'panoptic/obs_x_dict.pickle')\n",
    "obs_x_dict = pd.read_pickle('panoptic/obs_x_dict.pickle')\n",
    "obs_x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large grid search CDFs already computed (r = 0 to 8, eta = 0 to 3.9)\n",
    "all_cdfs = combine_pickles('scipy_10000') | combine_pickles('mtlb_10000') \n",
    "all_cdfs_df = pd.DataFrame({'(r,eta),cdf' : sorted(all_cdfs.items())})\n",
    "all_cdfs_df['r'] = pd.Series(all_cdfs_df[\"(r,eta),cdf\"].str[0].str[0])\n",
    "all_cdfs_df['eta'] = pd.Series(all_cdfs_df[\"(r,eta),cdf\"].str[0].str[1])\n",
    "all_cdfs_df['cdf'] = pd.Series(all_cdfs_df[\"(r,eta),cdf\"].str[1])\n",
    "\n",
    "create_scatter_plots_log_eta(all_cdfs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental cell demoing all the plots\n",
    "layer = 2\n",
    "obs_x = obs_x_dict[layer]\n",
    "all_ksstats, best_param, min_stat = gridsearch(obs_x, all_cdfs)\n",
    "df = all_cdfs_df.copy()\n",
    "total_samples = obs_x.size\n",
    "df['kstest_stat'] = all_ksstats\n",
    "df['kstest_pval'] = kstwo(n=total_samples).sf(all_ksstats)\n",
    "print(f\"Best parameters {(best_param)} with KS-test Statistic {np.round(min_stat, 4)} and pvalue {kstwo(n=total_samples).sf(min_stat)}, layer {layer} with num_samples={total_samples}\")\n",
    "distance, location = visualize_cdfs(obs_x, best_param[0], best_param[1], 10000, all_cdfs)\n",
    "create_scatter_plot(df, 'kstest_stat')\n",
    "create_scatter_plot(df, 'kstest_pval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[(df['r'] > 0.4) & (df['eta'] >= 0.3) & (df0['r'] < 1)]\n",
    "indices = df0.index\n",
    "x = np.array(df0['r'].loc[indices])\n",
    "y = np.array(df0['eta'].loc[indices])\n",
    "z = np.array(df0['kstest_stat'].loc[indices]) \n",
    "X, Y = np.meshgrid(df0['r'].unique(), df0['eta'].unique())\n",
    "\n",
    "dims_r = df0['r'].unique().size\n",
    "dims_eta = df0['eta'].unique().size\n",
    "fig, ax = plt.subplots()\n",
    "CS = ax.contour(x.reshape(dims_r, dims_eta), y.reshape(dims_r, dims_eta), z.reshape(dims_r, dims_eta), np.append(np.arange(0.04, 0.3, 0.02), 0.3), cmap =  'viridis')\n",
    "ax.clabel(CS, CS.levels, inline=True, fontsize=10)\n",
    "create_contour_plot(df0,'kstest_stat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splines = sorted(all_cdfs.items())\n",
    "[splines[i] for i, param in enumerate(sorted(all_cdfs)) if param[1] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([i for i, param in enumerate(sorted(all_cdfs)) if param[1] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_grid_df = pd.DataFrame(columns = ['layer', 'ksstats', 'best_param', 'kstest_stat', 'best_param_eta_0', 'kstest_stat_eta_0'])\n",
    "idx_eta_0 = [i for i, param in enumerate(sorted(all_cdfs)) if np.isclose(param[1], 0, atol = 1e-40)]\n",
    "sorted_params = sorted(all_cdfs)\n",
    "for i, layer in enumerate(np.arange(2, 5)):\n",
    "    sample = obs_x_dict[layer]\n",
    "    ksstats, best_param, min_stat = gridsearch(sample, all_cdfs)\n",
    "    ksstats_eta_0 = [ksstats[i] for i in idx_eta_0]\n",
    "    idx_min_ksstats_eta_0 = \n",
    "    large_grid_df.loc[i, :] = [layer, ksstats, best_param, min_stat, sorted_params[idx_min_ksstats_eta_0], ksstats[idx_min_ksstats_eta_0]]\n",
    "\n",
    "large_grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given that pvalue = 0.05 and I have _ samples, what should the kstest statistic be?\n",
    "cutoffs_df = pd.DataFrame(columns = ['layer', 'num_samples', 'kstest_stat_0.05_cutoff', 'kstest_stat_0.1_cutoff'])\n",
    "for i, layer in enumerate(np.arange(2, 9)):\n",
    "    num_points = obs_x_dict[layer].size\n",
    "    cutoffs_df.loc[i, :] = (layer, num_points, kstwo(n=num_points).isf(0.05), kstwo(n=num_points).isf(0.1))   \n",
    "cutoffs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_df = pd.read_csv('panoptic/CSVs/best_params_df_fine_grid.csv')\n",
    "best_params_df['n_0.05'] = best_params_df.apply(lambda row : find_n_fixed_pval_stat(row.iloc[3], row.iloc[1]), axis = 1)\n",
    "best_params_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_n_fixed_pval_stat(ksstat : float, n : int, cutoff= 0.05):\n",
    "    curr_pval = kstwo(n).sf(ksstat)\n",
    "    while not np.isclose(curr_pval, cutoff, atol=0.01):\n",
    "        if curr_pval < cutoff: \n",
    "            n = int(n/2)\n",
    "            curr_pval = kstwo(n).sf(ksstat)\n",
    "        elif curr_pval > cutoff:\n",
    "            n = int(n*1.5)\n",
    "            curr_pval = kstwo(n).sf(ksstat)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_descent(sample, initial_param, r_depth, eta_depth, layer, completed_r_depth = 1, completed_eta_depth = 1):\n",
    "    '''\n",
    "    Given a NumPy array `sample` and an initial guess for the parameters that minimize the kstest statistic `initial_param`,\n",
    "    computes the best fti parameters (r, eta) right to decimal points specified by `r_depth` and `eta_depth`. \n",
    "    Assumes that initial guess is right to 1 decimal place by default.\n",
    "    Example usage:\n",
    "    `coord_descent(obs_x_dict[4], (0.8, 3), 3, 2, 4)` will search through\n",
    "    r = range(0.70, 0.90, 0.01), eta = 3. Suppose best value is 0.80\n",
    "    r = range(0.780, 0.800, 0.001), eta = 3. Suppose best value is r=0.803 (3 decimals)\n",
    "    Then\n",
    "    r = 0.803, eta = range(2.9, 3.1, 0.01). Suppose best value is eta=3.01 (2 decimals)\n",
    "\n",
    "    returns 0.803, 3.01\n",
    "    '''\n",
    "    r_0, eta_0 = initial_param\n",
    "\n",
    "    for d in np.arange(completed_r_depth, r_depth):\n",
    "            \n",
    "        r_range = np.arange(r_0 - 10.0**(-d), r_0 + 10.0**(-d), 10.0**(-d-1)) \n",
    "        eta_range = [eta_0]\n",
    "        print(r_range, eta_range, r_0)\n",
    "        add_cdfs(r_range, eta_range, 10000, True, f'layer{layer}_')\n",
    "        layer_cdfs = combine_pickles(f'layer{layer}_10000')\n",
    "        ksstats, best_param, min_stat = gridsearch(sample, layer_cdfs)\n",
    "        r_0 = best_param[0]\n",
    "\n",
    "    for d in np.arange(completed_eta_depth, eta_depth):\n",
    "            \n",
    "        r_range = [r_0]\n",
    "        eta_range = np.arange(eta_0 - 10.0**(-d), eta_0 + 10.0**(-d), 10.0**(-d-1)) \n",
    "        print(r_range, eta_range, eta_0)\n",
    "        add_cdfs(r_range, eta_range, 10000, True, f'layer{layer}_')\n",
    "        layer_cdfs = combine_pickles(f'layer{layer}_10000')\n",
    "        ksstats, best_param, min_stat = gridsearch(sample, layer_cdfs)\n",
    "        eta_0 = best_param[1]\n",
    "\n",
    "    return (r_0, eta_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf_dict_to_many_pickle(large_dict, folder_path, items_per = 20):\n",
    "\n",
    "    dict_keys = sorted(large_dict) \n",
    "    i = 0\n",
    "    \n",
    "    for k in dict_keys:\n",
    "        \n",
    "        small_dict = dict()\n",
    "        small_dict[k] = large_dict[k]\n",
    "        i += 1\n",
    "        min_r = round_to_sigfigs(min(k[0], min_r))\n",
    "        max_r = round_to_sigfigs(max(k[0], max_r))\n",
    "        min_eta = round_to_sigfigs(min(k[1], min_eta))\n",
    "        max_eta = round_to_sigfigs(max(k[1], max_eta))\n",
    "\n",
    "        if i == items_per:\n",
    "            with open(os.path.join(folder_path, f'{min_r}-{max_r}_{min_eta}-{max_eta}.pickle'), 'wb') as handle:\n",
    "                pickle.dump(small_dict, handle)\n",
    "            print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CDFs/layer2_10000/layer2_10000.pickle', 'rb') as handle:\n",
    "    big_dict = pickle.load(handle)\n",
    "big_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf_dict_to_many_pickle(big_dict, 'CDFs/testing_many_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_descent(obs_x_dict[4], (0.8, 3), 3, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch(obs_x_dict[4], combine_pickles('layer4_10000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Creates validation dataframes \n",
    "# For now, it caps out at 6. For layer 7 and up it just defaults to 2.9, 0\n",
    "\n",
    "# for layer in range(6, 8):\n",
    "#     obs_x = create_obs_x(data_dict, layer)\n",
    "#     df = make_layer_df(obs_x, all_cdfs_df)\n",
    "#     total_samples = obs_x.size\n",
    "#     all_num_samples = np.sort(np.append(5*10**np.arange(3.0, np.floor(np.log10(total_samples))), 10**np.arange(3.0, np.ceil(np.log10(total_samples)))))\n",
    "#     print(list(all_num_samples))\n",
    "#     np.random.seed(42)\n",
    "#     x = obs_x[np.random.permutation(total_samples)]\n",
    "#     val_df = pd.concat([val_df_fixed_num(x, n, all_cdfs_df) for n in all_num_samples])\n",
    "#     val_df.to_csv(f'panoptic/CSVs/val_df{layer}_{cdfs_name}.csv')\n",
    "#     val_df.value_counts(['r', 'eta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv(f'panoptic/CSVs/val_df{4}.csv', index_col='Unnamed: 0')\n",
    "print(val_df.value_counts(['r', 'eta'])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))  # Create a figure with two subplots\n",
    "\n",
    "for layer in np.arange(layer, layer+1):\n",
    "    #obs_x = obs_x_dict[layer]\n",
    "    #df = df_dict[layer]\n",
    "    total_samples = obs_x.size\n",
    "    x = obs_x[np.random.permutation(total_samples)]\n",
    "    val_df = pd.read_csv(f'panoptic/CSVs/val_df{layer}_{cdfs_name}.csv', index_col='Unnamed: 0')\n",
    "\n",
    "    # Scatter plot\n",
    "    sns.scatterplot(val_df.drop(['kstest_stat', 'kstest_pval'], axis=1), x='r', y='eta', palette='bright', hue='num_samples', alpha=0.4, ax=ax1)\n",
    "    r, eta = best_params_df.loc[layer]['r'], best_params_df.loc[layer]['eta']\n",
    "    ax1.scatter(x=r, y=eta, marker=\"*\", label='all_data', s=60, color='xkcd:shamrock green', alpha=0.7)\n",
    "    ax1.set_title(f'KS-Test Statistic minimizing parameters for subsets of layer {layer} data')\n",
    "    print(r, eta)\n",
    "    ax1.legend()\n",
    "\n",
    "    # KDE plot\n",
    "    sns.kdeplot(val_df.drop(['kstest_stat', 'kstest_pval'], axis=1), x='r', y='eta', palette='bright', hue='num_samples', alpha=0.4, ax=ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# TODO: Put plots side by side\n",
    "for layer in np.arange(layer, layer+1):\n",
    "    obs_x = obs_x_dict[layer]\n",
    "    df = df_dict[layer]\n",
    "    total_samples = obs_x.size\n",
    "    x = obs_x[np.random.permutation(total_samples)]\n",
    "    val_df = pd.read_csv(f'panoptic/CSVs/val_df{layer}.csv', index_col='Unnamed: 0')\n",
    "    sns.scatterplot(val_df.drop(['kstest_stat', 'kstest_pval'], axis = 1), x = 'r', y = 'eta', palette = 'bright', hue = 'num_samples', alpha = 0.4)\n",
    "    r, eta, = best_params_df.loc[layer]['r'], best_params_df.loc[layer]['eta']\n",
    "    plt.scatter(x = r, y = eta, marker=\"*\", label = 'all_data', s = 60, color = 'xkcd:shamrock green', alpha = 0.7)\n",
    "    plt.title(f'KS-Test Statistic minimizing parameters for subsets of layer {layer} data')\n",
    "    print(r, eta)\n",
    "    plt.legend()\n",
    "    \n",
    "    sns.kdeplot(val_df.drop(['kstest_stat', 'kstest_pval'], axis = 1), x = 'r', y = 'eta', palette = 'bright', hue = 'num_samples', alpha = 0.4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = 6\n",
    "val_df = pd.read_csv(f'panoptic/CSVs/val_df{layer}.csv', index_col='Unnamed: 0')\n",
    "mask = val_df['num_samples'] == 100\n",
    "sns.kdeplot(val_df.drop(['kstest_pval'], axis = 1)[mask], x = 'r', y = 'eta', fill=True)\n",
    "r, eta, = best_params_df.loc[layer]['r'], best_params_df.loc[layer]['eta']\n",
    "plt.scatter(x = r, y = eta, marker=\"*\", label = 'all_data', s = 60, color = 'xkcd:shamrock green', alpha = 0.7)\n",
    "plt.title('Validation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
