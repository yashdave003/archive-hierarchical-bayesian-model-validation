{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "DATASET = \"agriVision\"\n",
    "FINAL_DATA_NAME = 'approx1e5-agriVision-fourier' # + channel\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"agriVision-RGB-cleaned\"\n",
    "SAVE_DF = False\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','agriVision')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir\n",
    "BATCH_NUM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))\n",
    "freq_df = pd.read_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"), index_col= [\"dataset\", \"transform\", \"group\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'batch 1', 'batch 3', 'batch 2']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = [os.path.join(data_dir, f\"full-{RAW_DATA_SUFFIX}\", filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(os.path.join(data_dir, f\"full-{RAW_DATA_SUFFIX}\"))\n",
    "file_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch1-agriVision-RGB-cleaned\n",
      "batch2-agriVision-RGB-cleaned\n",
      "toy-agriVision-RGB-cleaned\n",
      "batch0-agriVision-RGB-cleaned\n",
      "full-agriVision-RGB-cleaned\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008052940675034493, 0.009260881776289667, 0.010650014042733115, 0.012247516149143082, 0.014084643571514543, 0.016197340107241723, 0.01862694112332798, 0.021420982291827175, 0.02463412963560125, 0.028329249080941435, 0.03257863644308265, 0.037465431909545044, 0.0430852466959768, 0.04954803370037331, 0.056980238755429305, 0.0655272745687437, 0.07535636575405526, 0.08665982061716354, 0.09965879370973807, 0.11460761276619877, 0.13179875468112856, 0.15156856788329784, 0.1743038530657925, 0.20044943102566135, 0.23051684567951053, 0.2650943725314371, 0.30485852841115263, 0.3505873076728255, 0.4031754038237493, 0.4636517143973116, 0.5331994715569083, 0.6131793922904445, 0.7051563011340111]\n"
     ]
    }
   ],
   "source": [
    "#Values obtained from plots in agriVisionFourierEDA.ipynb\n",
    "STARTING_VALUE = 0.008052940675034493\n",
    "ENDING_VALUE =0.6162627813472334\n",
    "MULT_FACTOR = 1.15\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"full-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")\n",
    "splits = getSplits(STARTING_VALUE,ENDING_VALUE, MULT_FACTOR)\n",
    "print(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [02:09<00:00, 34.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008052940675034493 0.009260881776289667 0.010650014042733115\n",
      " 0.012247516149143082 0.014084643571514543 0.016197340107241723\n",
      " 0.01862694112332798 0.021420982291827175 0.02463412963560125\n",
      " 0.028329249080941435 0.03257863644308265 0.037465431909545044\n",
      " 0.0430852466959768 0.04954803370037331 0.056980238755429305\n",
      " 0.0655272745687437 0.07535636575405526 0.08665982061716354\n",
      " 0.09965879370973807 0.11460761276619877 0.13179875468112856\n",
      " 0.15156856788329784 0.1743038530657925 0.20044943102566135\n",
      " 0.23051684567951053 0.2650943725314371 0.30485852841115263\n",
      " 0.3505873076728255 0.4031754038237493 0.4636517143973116\n",
      " 0.5331994715569083 0.6131793922904445 0.7051563011340111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:56<00:00,  1.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[-392795.28, 86206.02, -292061.4, -115114.78, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[833.4166, -1882.7662, -5946.4146, -568.0247, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[-984.8187, 13746.786, 3671.025, -4370.1533, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[920.325, -14458.394, 1362.3522, -1214.0748, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[-3350.686, 3087.8435, 5572.776, -85.52046, 64...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1     red                              (0.0, 0.0078125)   \n",
       "1     2     red  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3     red           (0.009765625, 0.010517900013934578)   \n",
       "3     4     red   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5     red  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [-392795.28, 86206.02, -292061.4, -115114.78, ...  \n",
       "1                  3  [833.4166, -1882.7662, -5946.4146, -568.0247, ...  \n",
       "2                  3  [-984.8187, 13746.786, 3671.025, -4370.1533, 3...  \n",
       "3                  4  [920.325, -14458.394, 1362.3522, -1214.0748, -...  \n",
       "4                  6  [-3350.686, 3087.8435, 5572.776, -85.52046, 64...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [01:57<00:00, 38.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008052940675034493 0.009260881776289667 0.010650014042733115\n",
      " 0.012247516149143082 0.014084643571514543 0.016197340107241723\n",
      " 0.01862694112332798 0.021420982291827175 0.02463412963560125\n",
      " 0.028329249080941435 0.03257863644308265 0.037465431909545044\n",
      " 0.0430852466959768 0.04954803370037331 0.056980238755429305\n",
      " 0.0655272745687437 0.07535636575405526 0.08665982061716354\n",
      " 0.09965879370973807 0.11460761276619877 0.13179875468112856\n",
      " 0.15156856788329784 0.1743038530657925 0.20044943102566135\n",
      " 0.23051684567951053 0.2650943725314371 0.30485852841115263\n",
      " 0.3505873076728255 0.4031754038237493 0.4636517143973116\n",
      " 0.5331994715569083 0.6131793922904445 0.7051563011340111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:52<00:00,  1.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[-323678.72, 38747.445, -50607.49, -267776.28,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[-672.2614, -3419.6807, -389.27072, -141.31136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[-6398.016, 12236.549, 3216.7275, -5766.7983, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[3850.5598, -15950.094, -4335.4985, -3249.9104...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>blue</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[4255.858, 3879.4197, -5601.3423, -1108.9846, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1    blue                              (0.0, 0.0078125)   \n",
       "1     2    blue  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3    blue           (0.009765625, 0.010517900013934578)   \n",
       "3     4    blue   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5    blue  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [-323678.72, 38747.445, -50607.49, -267776.28,...  \n",
       "1                  3  [-672.2614, -3419.6807, -389.27072, -141.31136...  \n",
       "2                  3  [-6398.016, 12236.549, 3216.7275, -5766.7983, ...  \n",
       "3                  4  [3850.5598, -15950.094, -4335.4985, -3249.9104...  \n",
       "4                  6  [4255.858, 3879.4197, -5601.3423, -1108.9846, ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [01:58<00:00, 37.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008052940675034493 0.009260881776289667 0.010650014042733115\n",
      " 0.012247516149143082 0.014084643571514543 0.016197340107241723\n",
      " 0.01862694112332798 0.021420982291827175 0.02463412963560125\n",
      " 0.028329249080941435 0.03257863644308265 0.037465431909545044\n",
      " 0.0430852466959768 0.04954803370037331 0.056980238755429305\n",
      " 0.0655272745687437 0.07535636575405526 0.08665982061716354\n",
      " 0.09965879370973807 0.11460761276619877 0.13179875468112856\n",
      " 0.15156856788329784 0.1743038530657925 0.20044943102566135\n",
      " 0.23051684567951053 0.2650943725314371 0.30485852841115263\n",
      " 0.3505873076728255 0.4031754038237493 0.4636517143973116\n",
      " 0.5331994715569083 0.6131793922904445 0.7051563011340111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:58<00:00,  1.78s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[-229692.56, 61258.156, 73333.73, -276005.66, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[-719.6381, 5378.037, 2973.795, -477.2372, 130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[-6178.866, 9243.546, 1582.8497, -5807.768, 29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[2787.502, -7590.3486, -851.69037, -3147.1912,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>green</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[4676.5986, -2156.7576, -1644.2096, -1172.3566...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1   green                              (0.0, 0.0078125)   \n",
       "1     2   green  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3   green           (0.009765625, 0.010517900013934578)   \n",
       "3     4   green   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5   green  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [-229692.56, 61258.156, 73333.73, -276005.66, ...  \n",
       "1                  3  [-719.6381, 5378.037, 2973.795, -477.2372, 130...  \n",
       "2                  3  [-6178.866, 9243.546, 1582.8497, -5807.768, 29...  \n",
       "3                  4  [2787.502, -7590.3486, -851.69037, -3147.1912,...  \n",
       "4                  6  [4676.5986, -2156.7576, -1644.2096, -1172.3566...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [02:18<00:00, 32.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008052940675034493 0.009260881776289667 0.010650014042733115\n",
      " 0.012247516149143082 0.014084643571514543 0.016197340107241723\n",
      " 0.01862694112332798 0.021420982291827175 0.02463412963560125\n",
      " 0.028329249080941435 0.03257863644308265 0.037465431909545044\n",
      " 0.0430852466959768 0.04954803370037331 0.056980238755429305\n",
      " 0.0655272745687437 0.07535636575405526 0.08665982061716354\n",
      " 0.09965879370973807 0.11460761276619877 0.13179875468112856\n",
      " 0.15156856788329784 0.1743038530657925 0.20044943102566135\n",
      " 0.23051684567951053 0.2650943725314371 0.30485852841115263\n",
      " 0.3505873076728255 0.4031754038237493 0.4636517143973116\n",
      " 0.5331994715569083 0.6131793922904445 0.7051563011340111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:57<00:00,  1.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[-289135.4, 66142.73, -50019.508, -226949.62, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.008052940675034493, 0.008734640537108554)</td>\n",
       "      <td>3</td>\n",
       "      <td>[-249.95715, 2204.3054, -76.14266, -466.03033,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.009765625, 0.010517900013934578)</td>\n",
       "      <td>3</td>\n",
       "      <td>[-4650.7305, 10929.843, 2393.1091, -5372.8135,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.011048543456039806, 0.01188039556698871)</td>\n",
       "      <td>4</td>\n",
       "      <td>[2350.3125, -10595.459, -586.98206, -2580.778,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>gray</td>\n",
       "      <td>(0.012352647110032733, 0.014084184669781208)</td>\n",
       "      <td>6</td>\n",
       "      <td>[2228.811, 99.19349, 61.99873, -840.1596, 4009...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   band channel                           magnitude_endpoints  \\\n",
       "0     1    gray                              (0.0, 0.0078125)   \n",
       "1     2    gray  (0.008052940675034493, 0.008734640537108554)   \n",
       "2     3    gray           (0.009765625, 0.010517900013934578)   \n",
       "3     4    gray   (0.011048543456039806, 0.01188039556698871)   \n",
       "4     5    gray  (0.012352647110032733, 0.014084184669781208)   \n",
       "\n",
       "   unique_magnitudes                                               data  \n",
       "0                 10  [-289135.4, 66142.73, -50019.508, -226949.62, ...  \n",
       "1                  3  [-249.95715, 2204.3054, -76.14266, -466.03033,...  \n",
       "2                  3  [-4650.7305, 10929.843, 2393.1091, -5372.8135,...  \n",
       "3                  4  [2350.3125, -10595.459, -586.98206, -2580.778,...  \n",
       "4                  6  [2228.811, 99.19349, 61.99873, -840.1596, 4009...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"fourier\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "channel_fr['data'] = channel_fr['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = np.mean(channel_fr[(channel_fr['band'] == group)]['magnitude_endpoints'].iloc[0])\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'channel_fr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m channel_fr, group_data_map, group_data_map_size\n",
      "\u001b[0;31mNameError\u001b[0m: name 'channel_fr' is not defined"
     ]
    }
   ],
   "source": [
    "del channel_fr, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_DATA_NAME = 'approx1e5-agriVision-wavelet'\n",
    "if BATCH_NUM is None:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"full-{RAW_DATA_SUFFIX}\")\n",
    "else:\n",
    "    batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4500/4500 [01:33<00:00, 48.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099611</td>\n",
       "      <td>L1</td>\n",
       "      <td>[12.37854, 388.76587, -71.011154, -525.40607, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>D</td>\n",
       "      <td>[-56.85054, 10.112775, -65.61645, 3.6756237, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>H</td>\n",
       "      <td>[426.77856, 36.807053, 2.2234993, 41.115826, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>V</td>\n",
       "      <td>[-458.58713, 52.57764, -45.266056, -4.2271876,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>red</td>\n",
       "      <td>3</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-192.24008, 1.2320688, -6.463406, 114.53845, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0     red      1   0.099611          L1   \n",
       "1     red      2   0.110679           D   \n",
       "2     red      2   0.110679           H   \n",
       "3     red      2   0.110679           V   \n",
       "4     red      3   0.124514           D   \n",
       "\n",
       "                                                data  \n",
       "0  [12.37854, 388.76587, -71.011154, -525.40607, ...  \n",
       "1  [-56.85054, 10.112775, -65.61645, 3.6756237, -...  \n",
       "2  [426.77856, 36.807053, 2.2234993, 41.115826, 3...  \n",
       "3  [-458.58713, 52.57764, -45.266056, -4.2271876,...  \n",
       "4  [-192.24008, 1.2320688, -6.463406, 114.53845, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"red\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "                             \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1416/4500 [00:32<01:11, 43.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m TRANSFORM \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwavelet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m channel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m channel_wv \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_wavelet_basis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_opener\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnpz_opener\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m channel_wv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m channel_wv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : x\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SAVE_DF:\n",
      "File \u001b[0;32m~/Desktop/hierarchical-bayesian-model-validation/utilities/transform.py:63\u001b[0m, in \u001b[0;36mconvert_to_wavelet_basis\u001b[0;34m(folder_dir, color, basis, image_func, debug, image_opener)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image_opener \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[43mimage_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[:,:,c]\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m         image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(file_list[k]))[:,:,c]\n",
      "File \u001b[0;32m~/Desktop/hierarchical-bayesian-model-validation/utilities/transform.py:23\u001b[0m, in \u001b[0;36mnpz_opener\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnpz_opener\u001b[39m(path):\n\u001b[1;32m     22\u001b[0m     npz_file \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(path)\n\u001b[0;32m---> 23\u001b[0m     array_data \u001b[38;5;241m=\u001b[39m \u001b[43mnpz_file\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnpz_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array_data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/site-packages/numpy/lib/npyio.py:256\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mMAGIC_PREFIX:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(key)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mread(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/site-packages/numpy/lib/format.py:831\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    829\u001b[0m             read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[1;32m    830\u001b[0m             read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m dtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[0;32m--> 831\u001b[0m             data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    832\u001b[0m             array[i:i\u001b[38;5;241m+\u001b[39mread_count] \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    833\u001b[0m                                                      count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/site-packages/numpy/lib/format.py:966\u001b[0m, in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 966\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[1;32m    968\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/zipfile.py:929\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n\u001b[0;32m--> 929\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readbuffer \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/NewResearch/lib/python3.10/zipfile.py:1005\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_type \u001b[38;5;241m==\u001b[39m ZIP_DEFLATED:\n\u001b[1;32m   1004\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMIN_READ_SIZE)\n\u001b[0;32m-> 1005\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1006\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39meof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m                  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_left \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eof:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"green\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:04<00:00, 365.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>L1</td>\n",
       "      <td>[0.20727114, -33.177452, -23.717556, -104.1030...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-26.155533, 6.1044655, 21.780111, 24.545807, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>H</td>\n",
       "      <td>[-90.20362, -75.99399, 19.310474, -11.829856, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>V</td>\n",
       "      <td>[76.4653, 12.720116, -29.556787, -10.373663, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>D</td>\n",
       "      <td>[53.602417, 3.668749, -16.509668, -0.57486, -1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0    blue      1   0.110679          L1   \n",
       "1    blue      2   0.124514           D   \n",
       "2    blue      2   0.124514           H   \n",
       "3    blue      2   0.124514           V   \n",
       "4    blue      3   0.142301           D   \n",
       "\n",
       "                                                data  \n",
       "0  [0.20727114, -33.177452, -23.717556, -104.1030...  \n",
       "1  [-26.155533, 6.1044655, 21.780111, 24.545807, ...  \n",
       "2  [-90.20362, -75.99399, 19.310474, -11.829856, ...  \n",
       "3  [76.4653, 12.720116, -29.556787, -10.373663, 0...  \n",
       "4  [53.602417, 3.668749, -16.509668, -0.57486, -1...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"blue\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "    \n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers being used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1590/1590 [00:04<00:00, 339.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>frequency</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gray</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>L1</td>\n",
       "      <td>[-6.1360106, 35.824085, -12.069928, -92.59161,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>D</td>\n",
       "      <td>[-20.23139, 5.5501356, 18.585161, 14.010576, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>H</td>\n",
       "      <td>[-54.903618, -72.86237, 8.412701, -6.4397974, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gray</td>\n",
       "      <td>2</td>\n",
       "      <td>0.124514</td>\n",
       "      <td>V</td>\n",
       "      <td>[55.306328, 9.492829, -24.910969, -6.03024, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gray</td>\n",
       "      <td>3</td>\n",
       "      <td>0.142301</td>\n",
       "      <td>D</td>\n",
       "      <td>[36.00795, 3.1733897, -9.826171, -1.8638246, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel  layer  frequency orientation  \\\n",
       "0    gray      1   0.110679          L1   \n",
       "1    gray      2   0.124514           D   \n",
       "2    gray      2   0.124514           H   \n",
       "3    gray      2   0.124514           V   \n",
       "4    gray      3   0.142301           D   \n",
       "\n",
       "                                                data  \n",
       "0  [-6.1360106, 35.824085, -12.069928, -92.59161,...  \n",
       "1  [-20.23139, 5.5501356, 18.585161, 14.010576, -...  \n",
       "2  [-54.903618, -72.86237, 8.412701, -6.4397974, ...  \n",
       "3  [55.306328, 9.492829, -24.910969, -6.03024, 0....  \n",
       "4  [36.00795, 3.1733897, -9.826171, -1.8638246, -...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORM = \"wavelet\"\n",
    "channel = \"gray\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "channel_wv['data'] = channel_wv['data'].apply(lambda x : x.astype(np.float32))\n",
    "if SAVE_DF:\n",
    "    if BATCH_NUM is None:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "    else:\n",
    "        pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"dataframes/batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    freq_df.loc[DATASET, TRANSFORM, group] = channel_wv[(channel_wv['layer'] == group)]['frequency'].iloc[0]\n",
    "freq_df.to_csv(os.path.join(ROOT_DIR, \"transformed-data\", f\"master-frequency-map.csv\"))\n",
    "\n",
    "if BATCH_NUM is None:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "else:\n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del channel_wv, group_data_map, group_data_map_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_backup2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
