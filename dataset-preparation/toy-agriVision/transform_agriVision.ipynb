{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import git\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "ROOT_DIR = Path(git.Repo('.', search_parent_directories=True).working_tree_dir)\n",
    "\n",
    "FINAL_DATA_NAME = 'approx1e5-agriVision-fourier' # + channel\n",
    "CONSTANT_SAMPLE_SIZE = int(1e5)\n",
    "RAW_DATA_SUFFIX = \"agriVision-RGB-cleaned\"\n",
    "\n",
    "data_dir = os.path.join(ROOT_DIR, 'raw-data','agriVision')\n",
    "file_list = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(data_dir)\n",
    "data_dir"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\yashd\\\\Desktop\\\\hierarchical-bayesian-model-validation\\\\raw-data\\\\agriVision'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, \"utilities\"))\n",
    "from transform import *\n",
    "os.chdir(os.path.join(ROOT_DIR, \"dataset-preparation\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "file_list = [os.path.join(data_dir, f\"full-{RAW_DATA_SUFFIX}\", filename) for filename in os.listdir(data_dir)]\n",
    "file_names = os.listdir(os.path.join(data_dir, f\"full-{RAW_DATA_SUFFIX}\"))\n",
    "file_names[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['11IE4DKTR_11556-9586-12068-10098.jpg',\n",
       " '11IE4DKTR_6121-684-6633-1196.jpg',\n",
       " '11TAQJ6ET_1124-8510-1636-9022.jpg',\n",
       " '11TAQJ6ET_1148-8089-1660-8601.jpg',\n",
       " '11TAQJ6ET_1288-961-1800-1473.jpg']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "'''Assuming No batching is required. Not applicable for agriVision'''\n",
    "\n",
    "# data_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", \"full-agriVision-RGB-cleaned\")\n",
    "\n",
    "# for channel in ['red', 'blue', 'green', 'gray', 'infrared']:\n",
    "\n",
    "#     channel_fr = convert_to_fourier_basis(data_dir, channel, debug = True)\n",
    "#     pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"full-agriVision-fourier-{channel}-df.pickle\"))\n",
    "\n",
    "#     min_group, max_group = 2, max(channel_fr['band'])\n",
    "#     group_data_map = dict()\n",
    "#     group_data_map_size = dict()\n",
    "#     for group in np.arange(min_group, max_group + 1):\n",
    "#         data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "#         group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "#         group_data_map_size[group] = data.size\n",
    "    \n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "#     pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Assuming No batching is required. Not applicable for agriVision'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "'''To split large dataset into many batches, only needs to be run once'''\n",
    "# k = 10000\n",
    "# target_dir = os.path.join(ROOT_DIR, 'raw-data', 'agriVision') # Where the batch{i} folders will be created\n",
    "# directorySplit(folder_dir = data_dir, target_dir = target_dir, name = RAW_DATA_SUFFIX, k = k)\n",
    "# print(f\"{len(file_names)//k} batches created\" )"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'To split large dataset into many batches, only needs to be run once'"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "'''Show all subsets of data in raw data folder that have already been created'''\n",
    "print(''.join([x+\"\\n\" for x in os.listdir(data_dir) if x.__contains__(RAW_DATA_SUFFIX)]))\n",
    "BATCH_NUM = 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch0-agriVision-RGB-cleaned\n",
      "batch1-agriVision-RGB-cleaned\n",
      "batch2-agriVision-RGB-cleaned\n",
      "batch3-agriVision-RGB-cleaned\n",
      "batch4-agriVision-RGB-cleaned\n",
      "batch5-agriVision-RGB-cleaned\n",
      "batch6-agriVision-RGB-cleaned\n",
      "batch7-agriVision-RGB-cleaned\n",
      "batch8-agriVision-RGB-cleaned\n",
      "full-agriVision-RGB-cleaned\n",
      "toy-agriVision-RGB-cleaned\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fourier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#Values obtained from plots in agriVisionFourierEDA.ipynb\n",
    "batch_dir = os.path.join(ROOT_DIR, \"raw-data\", \"agriVision\", f\"batch{BATCH_NUM}-{RAW_DATA_SUFFIX}\")\n",
    "splits = getSplits(0.008052940675034493,0.5282905274067067, 1.15)\n",
    "print(splits)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.008052940675034493, 0.010871469911296566, 0.014676484380250364, 0.01981325391333799, 0.02674789278300629, 0.0361096552570585, 0.04874803459702898, 0.06580984670598912, 0.08884329305308532, 0.11993844562166518, 0.161916901589248, 0.21858781714548484, 0.29509355314640456, 0.3983762967476462]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"red\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"blue\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"green\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True)\n",
    "pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"blue\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"gray\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True, image_opener = npz_opener)\n",
    "pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"infrared\"\n",
    "\n",
    "channel_fr = convert_to_fourier_basis(batch_dir, channel, split_list = splits, debug = True)\n",
    "pd.to_pickle(channel_fr, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_fr['band'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = channel_fr[(channel_fr['band'] == group)]['data'].iloc[0]\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_fr.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.00805294 0.01087147 0.01467648 0.01981325 0.02674789 0.03610966\n",
      " 0.04874803 0.06580985 0.08884329 0.11993845 0.1619169  0.21858782\n",
      " 0.29509355 0.3983763 ]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>band</th>\n",
       "      <th>channel</th>\n",
       "      <th>magnitude_endpoints</th>\n",
       "      <th>unique_magnitudes</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Infrared</td>\n",
       "      <td>(0.0, 0.0078125)</td>\n",
       "      <td>10</td>\n",
       "      <td>[80367.0, 464026.0, 265558.0, 232272.0, 394565...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Infrared</td>\n",
       "      <td>(0.008052940675034493, 0.010517900013934578)</td>\n",
       "      <td>6</td>\n",
       "      <td>[-671.8820488918707, 2292.7830400318353, -270....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Infrared</td>\n",
       "      <td>(0.011048543456039806, 0.014218964627501012)</td>\n",
       "      <td>11</td>\n",
       "      <td>[-596.3965045249346, -2458.981803649216, 759.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Infrared</td>\n",
       "      <td>(0.014874556847390447, 0.019628663322501738)</td>\n",
       "      <td>18</td>\n",
       "      <td>[-1869.7239977786285, -2382.1295181624646, 108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Infrared</td>\n",
       "      <td>(0.019918044974971814, 0.026565372087373914)</td>\n",
       "      <td>30</td>\n",
       "      <td>[-1665.8794472636714, 359.6725136568671, -538....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  band   channel                           magnitude_endpoints  \\\n",
       "0    1  Infrared                              (0.0, 0.0078125)   \n",
       "1    2  Infrared  (0.008052940675034493, 0.010517900013934578)   \n",
       "2    3  Infrared  (0.011048543456039806, 0.014218964627501012)   \n",
       "3    4  Infrared  (0.014874556847390447, 0.019628663322501738)   \n",
       "4    5  Infrared  (0.019918044974971814, 0.026565372087373914)   \n",
       "\n",
       "  unique_magnitudes                                               data  \n",
       "0                10  [80367.0, 464026.0, 265558.0, 232272.0, 394565...  \n",
       "1                 6  [-671.8820488918707, 2292.7830400318353, -270....  \n",
       "2                11  [-596.3965045249346, -2458.981803649216, 759.5...  \n",
       "3                18  [-1869.7239977786285, -2382.1295181624646, 108...  \n",
       "4                30  [-1665.8794472636714, 359.6725136568671, -538....  "
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Wavelet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "FINAL_DATA_NAME = 'approx1e5-agriVision-wavelet'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"red\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"green\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10554/10554 [01:28<00:00, 118.69it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>1</td>\n",
       "      <td>L1</td>\n",
       "      <td>[267.7968750000003, 388.21679687500034, 945.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>[-7.015624999999998, 5.251953124999998, -13.79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>[6.765624999999998, -31.357421875000036, 78.32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red</td>\n",
       "      <td>2</td>\n",
       "      <td>V</td>\n",
       "      <td>[-267.5468750000003, -60.439453125000085, -209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>[0.0, -8.875000000000002, 0.25000000000000006,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel layer orientation                                               data\n",
       "0     Red     1          L1  [267.7968750000003, 388.21679687500034, 945.17...\n",
       "1     Red     2           D  [-7.015624999999998, 5.251953124999998, -13.79...\n",
       "2     Red     2           H  [6.765624999999998, -31.357421875000036, 78.32...\n",
       "3     Red     2           V  [-267.5468750000003, -60.439453125000085, -209...\n",
       "4     Red     3           D  [0.0, -8.875000000000002, 0.25000000000000006,..."
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"blue\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Green</td>\n",
       "      <td>1</td>\n",
       "      <td>L1</td>\n",
       "      <td>[159.79101562500017, 913.0214843750011, 440.91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Green</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>[-54.748046875000064, 60.771484375000185, 6.72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Green</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>[64.33007812500007, 52.45507812500003, 16.5664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Green</td>\n",
       "      <td>2</td>\n",
       "      <td>V</td>\n",
       "      <td>[-90.8027343750001, 0.33007812499994316, -6.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Green</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>[9.527343750000007, 5.507812500000005, -2.4296...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel layer orientation                                               data\n",
       "0   Green     1          L1  [159.79101562500017, 913.0214843750011, 440.91...\n",
       "1   Green     2           D  [-54.748046875000064, 60.771484375000185, 6.72...\n",
       "2   Green     2           H  [64.33007812500007, 52.45507812500003, 16.5664...\n",
       "3   Green     2           V  [-90.8027343750001, 0.33007812499994316, -6.49...\n",
       "4   Green     3           D  [9.527343750000007, 5.507812500000005, -2.4296..."
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"gray\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "channel_wv.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "channel = \"infrared\"\n",
    "\n",
    "channel_wv = convert_to_wavelet_basis(batch_dir, channel, debug = True, image_opener = npz_opener)\n",
    "pd.to_pickle(channel_wv, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-df.pickle\"))\n",
    "\n",
    "\n",
    "min_group, max_group = 2, max(channel_wv['layer'])\n",
    "group_data_map = dict()\n",
    "group_data_map_size = dict()\n",
    "for group in np.arange(min_group, max_group + 1):\n",
    "    data = np.append(channel_wv[(channel_wv['orientation'] == 'H') & (channel_wv['layer'] == group)]['data'].iloc[0],\n",
    "                     channel_wv[(channel_wv['orientation'] == 'V') & (channel_wv['layer'] == group)]['data'].iloc[0])\n",
    "    group_data_map[group] = np.sort(data)[np.round(np.linspace(0, data.size - 1, min(data.size, CONSTANT_SAMPLE_SIZE))).astype(int)] \n",
    "    group_data_map_size[group] = data.size\n",
    "    \n",
    "    pd.to_pickle(group_data_map, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}.pickle\"))\n",
    "    pd.to_pickle(group_data_map_size, os.path.join(ROOT_DIR, \"transformed-data\", f\"batch{BATCH_NUM}{FINAL_DATA_NAME}-{channel}-size.pickle\"))\n",
    "\n",
    "ir_fr.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10 layers being used\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel</th>\n",
       "      <th>layer</th>\n",
       "      <th>orientation</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blue</td>\n",
       "      <td>1</td>\n",
       "      <td>L1</td>\n",
       "      <td>[190.46875000000023, 903.0976562500011, 474.31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>[-79.18359375000007, 59.93750000000008, -0.888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blue</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>[90.8710937500001, 49.05078124999999, -14.1269...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blue</td>\n",
       "      <td>2</td>\n",
       "      <td>V</td>\n",
       "      <td>[-121.25781250000013, -5.492187500000057, -8.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blue</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>[8.69140625000001, 37.976562500000036, -2.8476...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  channel layer orientation                                               data\n",
       "0    Blue     1          L1  [190.46875000000023, 903.0976562500011, 474.31...\n",
       "1    Blue     2           D  [-79.18359375000007, 59.93750000000008, -0.888...\n",
       "2    Blue     2           H  [90.8710937500001, 49.05078124999999, -14.1269...\n",
       "3    Blue     2           V  [-121.25781250000013, -5.492187500000057, -8.1...\n",
       "4    Blue     3           D  [8.69140625000001, 37.976562500000036, -2.8476..."
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 4,
  "interpreter": {
   "hash": "7e5f984cc8cd8c47dcd3acda73327432e6be76c353527f01c56663ba6bbc3ba9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}